# TransLingualMarvel-RoEn-MT
A Seq2Seq Neural Machine Translation project for Romanian to English. Leveraging Keras and LSTM architecture to enhance communication fluidity between languages.

Objective​

​

Importance of Machine Translation:​

Effortlessly facilitates mutual understanding across diverse languages.​

Aims to bridge the language gap, fostering global communication.​

​

Challenges in Romanian to English Translation:​

Explores the intricacies of translating between Romanian and English.​

Goes beyond word translation, focusing on capturing the unique expression of ideas in each language.​

​

Project Focus: Translingual Marvel:​

Specifically addresses challenges in Romanian to English translation.



Overview​

​

Objective: Translate Romanian sentences to English​

​

Model: LSTM Translingual Translator​

​

Model Type: Seq2Seq Neural Machine Translation​

​

Libraries Used: Keras, NLTK, Jiwer, Plotly, Tabulate​

​

Evaluation Metrics: WER, BLEU, METEOR


Training​

​

Hyperparameters:​

Batch Size: 64​

Learning Rate: 0.001​

Epochs: 20​

Validation Split: 0.1​

​

Loss Function: Sparse Categorical Crossentropy​

​

Optimizer: Adam


Evaluation Metrics​

​

WER (Word Error Rate): 0.2167​

​

BLEU Score: 0.8957​

​

METEOR Score: 0.7931​

​

Test Loss: 1.4607​

​

Cross Entropy Loss: 0.1672



Conclusion​

​

Successful exploration of "Translingual Marvel: Unveiling the Enigma of Romanian to English Machine Translation" with a focus on Seq2Seq Neural Machine Translation.​

​

Emphasis on efficient tokenization and Seq2Seq architecture optimizations as crucial elements for enhancing translation quality.​

​

Comprehensive evaluation using WER, BLEU, METEOR, and loss metrics, providing valuable insights into the model's performance.​

​

Strategic use of Keras, NLTK, Jiwer, Plotly, and Tabulate libraries for streamlined implementation and evaluation.​

​

Clear demonstration of the project's impact in fostering cross-cultural communication and understanding through machine translation.​

​

Reflection on the significance of lessons learned, paving the way for future innovations and improvements in the dynamic field of natural language processing.​
